{
  "2205.10981v1": {
    "title": "Improving Short Text Classification With Augmented Data Using GPT-3",
    "authors": [
      "Salvador Balkus",
      "Donghui Yan"
    ],
    "summary": "GPT-3 is a large-scale natural language model developed by OpenAI that can\nperform many different tasks, including topic classification. Although\nresearchers claim that it requires only a small number of in-context examples\nto learn a task, in practice GPT-3 requires these training examples to be\neither of exceptional quality or a higher quantity than easily created by hand.\nTo address this issue, this study teaches GPT-3 to classify whether a question\nis related to data science by augmenting a small training set with additional\nexamples generated by GPT-3 itself. This study compares two classifiers: the\nGPT-3 Classification Endpoint with augmented examples, and the GPT-3 Completion\nEndpoint with an optimal training set chosen using a genetic algorithm. We find\nthat while the augmented Completion Endpoint achieves upwards of 80 percent\nvalidation accuracy, using the augmented Classification Endpoint yields more\nconsistent accuracy on unseen examples. In this way, giving large-scale machine\nlearning models like GPT-3 the ability to propose their own additional training\nexamples can result in improved classification performance.",
    "pdf_url": "http://arxiv.org/pdf/2205.10981v1",
    "published": "2022-05-23"
  },
  "2212.00857v1": {
    "title": "a survey on GPT-3",
    "authors": [
      "Mingyu Zong",
      "Bhaskar Krishnamachari"
    ],
    "summary": "This paper provides an introductory survey to GPT-3. We cover some of the\nhistorical development behind this technology, some of the key features of\nGPT-3, and discuss the machine learning model and the datasets used. We survey\nboth academic and commercial efforts applying GPT-3 in diverse domains such as\ndeveloping conversational AI chatbots, software development, creative work,\ndomain knowledge, and business productivity. We discuss some of the challenges\nthat GPT-3 faces such as the problems of training complexity, bias, and\nhallucination/incorrect answers. We also discuss the future research\nopportunities in this area.",
    "pdf_url": "http://arxiv.org/pdf/2212.00857v1",
    "published": "2022-12-01"
  }
}